resume: 0
# wandb: 1
# project: FGVC_ZO_INT

data_provider:
  dataset: cars
  root: '~/dataset'
  num_classes: 196

  # dataset: cifar10
  # root: '~/dataset'
  # num_classes: 10

  # dataset: cifar100
  # root: '~/dataset'
  # num_classes: 100

  # dataset: cub
  # root: '~/dataset'
  # num_classes: 200

  # dataset: flowers
  # root: '~/dataset'
  # num_classes: 102
  
  # dataset: food
  # root: '~/dataset'
  # num_classes: 101
  # num_samples_per_class: 100

  # dataset: pets
  # root: '~/dataset'
  # num_classes: 37
  
  # dataset: aircraft
  # root: '~/dataset'
  # num_classes: 100

  # dataset: cifar10-c
  # root: '~/dataset'
  # num_classes: 10
  # severity: 5
  # train_n: 1000
  # corruption_type: defocus_blur
  # # corruption_type: [gaussian_noise, impulse_noise, shot_noise, fog, frost, snow, defocus_blur, elastic_transform, brightness, contrast, defocus_blur]
  # load_model_path: './assets/mcunet_in1_cifar10.pth'

  # base_batch_size: 1
  # base_batch_size: 128
  base_batch_size: 100

run_config:
  # warmup_epochs: 5
  n_epochs: 100
  # n_epochs: 2000

  ### no gradint accumulation
  bs256_lr: 0.1
  # bs256_lr: 0.01

  ### gradient accumulation setting. should use the corresponding lr of batch size 1 
  grad_accumulation_steps: 128

  # iteration_decay: 0

  # optimizer
  # optimizer_name: sgd
  # optimizer_name: sgd_nomom
  # optimizer_name: adam

  # optimizer_name: sgd_int
  # optimizer_name: sgd_int_nomom

  # optimizer_name: sgd_scale
  # optimizer_name: sgd_scale_nomom

  # optimizer_name: sgd_scale_int
  optimizer_name: sgd_scale_int_nomom

net_config:
  net_name: mcunet-5fps
  # net_name: mbv2-w0.35
  # net_name: proxyless-w0.3

backward_config:
  # quantize_gradient: 1
  # n_bit: 8

  ##### Full model
  enable_backward_config: 0

  ##### cls-only
  # enable_backward_config: 1
  # n_bias_update: 0
  # n_weight_update: 0

  ##### sparse update (100KB scheme): 88.84%
  # enable_backward_config: 1  
  # n_bias_update: 22
  # manual_weight_idx: 21-24-27-30-36-39
  # # weight_update_ratio: 1-1-1-1-0.125-0.25
  # weight_update_ratio: 1-1-1-1-1-1

  ##### PokeEngine
  # enable_backward_config: 1  
  # n_bias_update: 22
  # manual_weight_idx: 24-27-30-33
  # weight_update_ratio: 1-1-0.5-1

  ##### select 6 layers
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 9-12-15-21-24-30
  # # manual_weight_idx: 9-12-15-18-21-27
  # # manual_weight_idx: 6-9-12-15-18-21
  # weight_update_ratio: 1-1-1-1-1-1

  ##### update last 2 blocks
  # enable_backward_config: 1 
  # n_bias_update: 6
  # n_weight_update: 6

  ##### update last 6 blocks
  # enable_backward_config: 1 
  # n_bias_update: 24
  # n_weight_update: 24

  ##### bias-only
  # enable_backward_config: 1 
  # n_bias_update: 22
  # n_weight_update: 0

  ########## Corruption datasets ##########
  # freeze_fc: 1
  # only_update_selected_bias: 1

  ##### first 2 blocks
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 0-1-2-3-4-5
  # weight_update_ratio: 1-1-1-1-1-1

  ##### first 6 blocks
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17
  # weight_update_ratio: 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1

  ##### first 2 pw1
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 0-3-6
  # weight_update_ratio: 1-1-1

  ##### first 6 pw1
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 0-3-6-9-12-15-18-21
  # weight_update_ratio: 1-1-1-1-1-1-1-1

  ##### sparse first layers
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 9-12-15-21-27
  # weight_update_ratio: 1-1-1-1-1

  ##### customize 1 layer
  # enable_backward_config: 1  
  # n_bias_update: 42
  # manual_weight_idx: 0
  # weight_update_ratio: 1

train_config:
  # BP_grad_prune_ratio: 0.9
  ZO_grad_prune_ratio: 0.9
  # prune_method: top-k-param
  prune_method: random-k-param
  # prune_method: top-k-channel
  # prune_method: random-k-channel

  # layerwise_update: 'all'
  # layerwise_update: 'one'

  # layerwise_update_layer_list: ['1.7.conv.0', '1.8.conv.0', '1.9.conv.0', '1.10.conv.0', '1.12.conv.0', '1.13.conv.0']
  # layerwise_update_layer_list: ['1.6.conv.0', '1.7.conv.0', '1.8.conv.0', '1.9.conv.0', '1.10.conv.0', '1.11.conv.0', '1.12.conv.0', '1.13.conv.0']

  # train_scale: 1
  # train_normalization: 1

  # normalization_func: BN
  # normalization_func: GN
  # normalization_func: SSF

  # normalization_func: L1FRN
  # activation_func: TLU

  q_param_lr:  {
    'scale_y': 0.01,
    'scale_w': 0.01, 

    'gamma': 0.1,
    'beta': 0.1,
  }
  
ZO_Estim:
  en: True

  # fc_bp: False
  # fc_bp: cls_only
  fc_bp: 'partial_BP'
  # fc_bp: 'break_BP'

  name: ZO_Estim_MC
  n_sample: 10
  signSGD: False

  scale: sqrt-dim
  # scale: dim
  # scale: 100

  # trainable_param_list: all
  trainable_param_list: ['weight', 'bias']
  # trainable_param_list: ['weight']
  # trainable_param_list: ['bias', 'scale_y','zero_y','scale_w', 'gamma', 'beta']
  # trainable_param_list: ['1.7.conv.0.weight', '1.8.conv.0.weight', '1.9.conv.0.weight', '1.10.conv.0.weight', '1.12.conv.0.weight', '1.13.conv.0.weight']
  # trainable_param_list: ['1.7.conv.0.weight', '1.8.conv.0.weight', '1.9.conv.0.weight', '1.10.conv.0.weight', '1.12.conv.0.weight', '1.13.conv.0.weight', '1.10.conv.1.bias', '1.10.conv.2.bias', '1.11.conv.0.bias', '1.11.conv.1.bias', '1.11.conv.2.bias', '1.12.conv.0.bias', '1.12.conv.1.bias', '1.12.conv.2.bias', '1.13.conv.0.bias', '1.13.conv.1.bias', '1.13.conv.2.bias']
  
  # trainable_layer_list: block-all
  # trainable_layer_list: layer-all
  # trainable_layer_list: layer-first-20
  # trainable_layer_list: layer-last-30

  # trainable_layer_list: ['1.8']
  # trainable_layer_list: ['1.12', '1.13']
  # trainable_layer_list: ['1.7', '1.8', '1.9', '1.10', '1.11', '1.12', '1.13']
  trainable_layer_list: ['1.12.conv.0']
  # trainable_layer_list: ['1.12.conv.0', '1.13.conv.0']
  # trainable_layer_list: ['1.3.conv.0', '1.4.conv.0', '1.5.conv.0', '1.7.conv.0', '1.8.conv.0', '1.10.conv.0']
  # trainable_layer_list: ['1.7.conv.0', '1.8.conv.0', '1.9.conv.0', '1.10.conv.0']
  # trainable_layer_list: ['1.7.conv.0', '1.8.conv.0', '1.9.conv.0', '1.10.conv.0', '1.12.conv.0', '1.13.conv.0']
  # trainable_layer_list: ['1.6.conv.0', '1.7.conv.0', '1.8.conv.0', '1.9.conv.0', '1.10.conv.0', '1.11.conv.0', '1.12.conv.0', '1.13.conv.0']
  # trainable_layer_list: ['1.12.conv.0', '1.12.conv.1', '1.12.conv.2', '1.13.conv.0', '1.13.conv.1', '1.13.conv.2']

  estimate_method: forward
  # estimate_method: antithetic

  # sample_method: uniform
  # sample_method: gaussian
  sample_method: bernoulli
  # sample_method: coord_basis

  ############################## Activation Perturbation ##############################
  # obj_fn_type: classifier_layerwise
  # perturb_method: activation

  # sigma: 10

  # perturb_before_round: 0

  # sync_batch_perturb: 0
  # # sync_batch_perturb: 1

  ############################## Param Perturbation ##############################
  obj_fn_type: classifier_layerwise
  perturb_method: param

  sigma: {
    'weight': 1,
    'bias': 100,

    # 'scale_y': 0.01,
    # 'scale_w': 0.001,

    # 'gamma': 0.1,
    # 'beta': 0.1,
  }

  param_update_method: None
  # param_update_method: layerwise
  # param_update_method: blockwise
  # param_update_method: modelwise

  ############################## Weight Perturbation ##############################
  # obj_fn_type: classifier
  # perturb_method: batch
  
  # obj_fn_type: classifier_row
  # perturb_method: single

  # quantize_method: None
  # sigma: 0.01
  # quantize_method: u_fp-grad_fp
  # quantize_method: u_fp-grad_int

  # sigma: 1
  quantize_method: u_int-grad_fp
  # quantize_method: u_int-grad_int

  mask_method: None
  # mask_method: block-30
  # mask_method: layer

  prior_method: None
  # prior_method: last_grad_perturb
  # prior_method: mov_avg_perturb
  # prior_method: last_grad_neighbor